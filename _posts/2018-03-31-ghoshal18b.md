---
title: Learning Sparse Polymatrix Games in Polynomial Time and Sample Complexity
abstract: We consider the problem of learning sparse polymatrix games from observations
  of strategic interactions. We show that a polynomial time method based on $\ell_{1,2}$-group
  regularized logistic regression recovers a game, whose Nash equilibria are the $ε$-Nash
  equilibria of the game from which the data was generated (true game), in $O(m^4
  d^4 \log (pd))$ samples of strategy profiles — where $m$ is the maximum number of
  pure strategies of a player, $p$ is the number of players, and $d$ is the maximum
  degree of the game graph. Under slightly more stringent separability conditions
  on the payoff matrices of the true game, we show that our method learns a game with
  the exact same Nash equilibria as the true game. We also show that $Ω(d \log (pm))$
  samples are necessary for any method  to consistently recover a game, with the same
  Nash-equilibria as the true game, from observations of strategic interactions.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: ghoshal18b
month: 0
tex_title: Learning Sparse Polymatrix Games in Polynomial Time and Sample Complexity
firstpage: 1486
lastpage: 1494
page: 1486-1494
order: 1486
cycles: false
author:
- given: Asish
  family: Ghoshal
- given: Jean
  family: Honorio
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artficial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/ghoshal18b/ghoshal18b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/ghoshal18b/ghoshal18b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
