---
title: 'Boosting Variational Inference: an Optimization Perspective'
abstract: Variational inference is a popular technique to approximate a possibly intractable
  Bayesian posterior with a more tractable one. Recently, boosting variational inference
  has been proposed as a new paradigm to approximate the posterior by a mixture of
  densities by greedily adding components to the mixture. However, as is the case
  with many other variational inference algorithms, its theoretical properties have
  not been studied. In the present work, we study the convergence properties of this
  approach from a modern optimization viewpoint by establishing connections to the
  classic Frank-Wolfe algorithm. Our analyses yields novel theoretical insights regarding
  the sufficient conditions for convergence, explicit rates, and algorithmic simplifications.
  Since a lot of focus in previous works for variational inference has been on tractability,
  our work is especially important as a much needed attempt to bridge the gap between
  probabilistic models and their corresponding theoretical properties.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: locatello18a
month: 0
tex_title: 'Boosting Variational Inference: an Optimization Perspective'
firstpage: 464
lastpage: 472
page: 464-472
order: 464
cycles: false
author:
- given: Francesco
  family: Locatello
- given: Rajiv
  family: Khanna
- given: Joydeep
  family: Ghosh
- given: Gunnar
  family: Ratsch
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artficial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/locatello18a/locatello18a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/locatello18a/locatello18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
