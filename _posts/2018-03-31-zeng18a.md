---
title: Finding Global Optima in Nonconvex Stochastic Semidefinite Optimization with
  Variance Reduction
abstract: There is a recent surge of interest in nonconvex reformulations via low-rank
  factorization for stochastic convex semidefinite optimization problem in the purpose
  of efficiency and scalability. Compared with the original convex formulations, the
  nonconvex ones typically involve much fewer variables, allowing them to scale to
  scenarios with millions of variables. However, it opens a new challenge that under
  what conditions the nonconvex stochastic algorithms may find the global optima effectively
  despite their empirical success in applications. In this paper, we provide an answer
  that a stochastic gradient descent method with variance reduction, can be adapted
  to solve the nonconvex reformulation of the original convex problem, with a global
  linear convergence, i.e., converging to a global optimum exponentially fast, at
  a proper initial choice in the restricted strongly convex case. Experimental studies
  on both simulation and real-world applications on ordinal embedding are provided
  to show the effectiveness of the proposed algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zeng18a
month: 0
tex_title: Finding Global Optima in Nonconvex Stochastic Semidefinite Optimization
  with Variance Reduction
firstpage: 199
lastpage: 207
page: 199-207
order: 199
cycles: false
author:
- given: Jinshan
  family: ZENG
- given: Ke
  family: Ma
- given: Yuan
  family: Yao
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artificial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/zeng18a/zeng18a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/zeng18a/zeng18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
