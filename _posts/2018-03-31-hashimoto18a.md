---
title: Derivative free optimization via repeated classification
abstract: "  We develop a procedure for minimizing a function using $n$ batched function
  value measurements at each of $T$ rounds by using classifiers to identify a functionâ€™s
  sublevel set. We show that sufficiently accurate classifiers can achieve linear
  convergence rates, and show that the convergence rate is tied to the difficulty
  of active learning sublevel sets. Further, we show that the bootstrap is a computationally
  efficient approximation to the necessary classification scheme. The end result is
  a computationally efficient method requiring no tuning that consistently outperforms
  other methods on simulations, standard benchmarks, real-world DNA binding optimization,
  and airfoil design problems where batched function queries are natural."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hashimoto18a
month: 0
tex_title: Derivative free optimization via repeated classification
firstpage: 2027
lastpage: 2036
page: 2027-2036
order: 2027
cycles: false
author:
- given: Tatsunori
  family: Hashimoto
- given: Steve
  family: Yadlowsky
- given: John
  family: Duchi
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artficial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/hashimoto18a/hashimoto18a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
