---
title: Convergence of Value Aggregation for Imitation Learning
abstract: 'Value aggregation is a general framework for solving imitation learning
  problems. Based on the idea of data aggregation, it generates a policy sequence
  by iteratively interleaving policy optimization and evaluation in an online learning
  setting. While the existence of a good policy in the policy sequence can be guaranteed
  non-asymptotically, little is known about the convergence of the sequence or the
  performance of the last policy. In this paper, we debunk the common belief that
  value aggregation always produces a convergent policy sequence with improving performance.
  Moreover, we identify a critical stability condition for convergence and provide
  a tight non-asymptotic bound on the performance of the last policy. These new theoretical
  insights let us stabilize problems with regularization, which removes the inconvenient
  process of identifying the best policy in the policy sequence in stochastic problems. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cheng18c
month: 0
tex_title: Convergence of Value Aggregation for Imitation Learning
firstpage: 1801
lastpage: 1809
page: 1801-1809
order: 1801
cycles: false
author:
- given: Ching-An
  family: Cheng
- given: Byron
  family: Boots
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artficial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/cheng18c/cheng18c.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/cheng18c/cheng18c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
