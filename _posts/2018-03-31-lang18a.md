---
title: Optimality of Approximate Inference Algorithms on Stable Instances
abstract: Approximate algorithms for structured prediction problems—such as LP 
  relaxations and the popular 
  α-expansion algorithm (Boykov et al. 2001)—typically far exceed
  their theoretical performance guarantees on real-world instances. These algorithms
  often find solutions that are very close to optimal. The goal of this paper is to
  partially explain the performance of α-expansion and an LP relaxation algorith, 
  on MAP inference in Ferromagnetic
  Potts models (FPMs). Our main results give stability conditions under which these
  two algorithms provably recover the optimal MAP solution. These theoretical
  result complement numerous empirical observations of good performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: lang18a
month: 0
tex_title: Alpha-expansion is Exact on Stable Instances
firstpage: 1157
lastpage: 1166
page: 1157-1166
order: 1157
cycles: false
author:
- given: Hunter
  family: Lang
- given: David
  family: Sontag
- given: Aravindan
  family: Vijayaraghavan
date: 2018-03-31
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-First International Conference on Artficial
  Intelligence and Statistics
volume: '84'
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 3
  - 31
pdf: http://proceedings.mlr.press/v84/lang18a/lang18a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v84/lang18a/lang18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
